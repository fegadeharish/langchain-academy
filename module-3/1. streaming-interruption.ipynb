{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c9e547f",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-3/streaming-interruption.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239464-lesson-1-streaming)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319adfec-2d0a-49f2-87f9-275c4a32add2",
   "metadata": {},
   "source": [
    "# Streaming\n",
    "\n",
    "## Review\n",
    "\n",
    "In module 2, covered a few ways to customize graph state and memory.\n",
    " \n",
    "We built up to a Chatbot with external memory that can sustain long-running conversations. \n",
    "\n",
    "## Goals\n",
    "\n",
    "This module will dive into `human-in-the-loop`, which builds on memory and allows users to interact directly with graphs in various ways. \n",
    "\n",
    "To set the stage for `human-in-the-loop`, we'll first dive into streaming, which provides several ways to visualize graph output (e.g., node state or chat model tokens) over the course of execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db024d1f-feb3-45a0-a55c-e7712a1feefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langgraph langchain_openai langgraph_sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d7e41b-c6ba-4e47-b645-6c110bede549",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "\n",
    "LangGraph is built with [first class support for streaming](https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming).\n",
    "\n",
    "Let's set up our Chatbot from Module 2, and show various way to stream outputs from the graph during execution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b430d92-f595-4322-a56e-06de7485daa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0682fc",
   "metadata": {},
   "source": [
    "Note that we use `RunnableConfig` with `call_model` to enable token-wise streaming. This is [only needed with python < 3.11](https://langchain-ai.github.io/langgraph/how-tos/streaming-tokens/). We include in case you are running this notebook in CoLab, which will use python 3.x. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d7321e0-0d99-4efe-a67b-74c12271859b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "# LLM\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0) \n",
    "\n",
    "# State \n",
    "class State(MessagesState):\n",
    "    summary: str\n",
    "\n",
    "# Define the logic to call the model\n",
    "def call_model(state: State, config: RunnableConfig):\n",
    "    \n",
    "    # Get summary if it exists\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # If there is summary, then we add it\n",
    "    if summary:\n",
    "        \n",
    "        # Add summary to system message\n",
    "        system_message = f\"Summary of conversation earlier: {summary}\"\n",
    "\n",
    "        # Append summary to any newer messages\n",
    "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "    \n",
    "    else:\n",
    "        messages = state[\"messages\"]\n",
    "    \n",
    "    response = model.invoke(messages, config)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def summarize_conversation(state: State):\n",
    "    \n",
    "    # First, we get any existing summary\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # Create our summarization prompt \n",
    "    if summary:\n",
    "        \n",
    "        # A summary already exists\n",
    "        summary_message = (\n",
    "            f\"This is summary of the conversation to date: {summary}\\n\\n\"\n",
    "            \"Extend the summary by taking into account the new messages above:\"\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        summary_message = \"Create a summary of the conversation above:\"\n",
    "\n",
    "    # Add prompt to our history\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    # Delete all but the 2 most recent messages\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "    return {\"summary\": response.content, \"messages\": delete_messages}\n",
    "\n",
    "# Determine whether to end or summarize the conversation\n",
    "def should_continue(state: State):\n",
    "    \n",
    "    \"\"\"Return the next node to execute.\"\"\"\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # If there are more than six messages, then we summarize the conversation\n",
    "    if len(messages) > 6:\n",
    "        return \"summarize_conversation\"\n",
    "    \n",
    "    # Otherwise we can just end\n",
    "    return END\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"conversation\", call_model)\n",
    "workflow.add_node(summarize_conversation)\n",
    "\n",
    "# Set the entrypoint as conversation\n",
    "workflow.add_edge(START, \"conversation\")\n",
    "workflow.add_conditional_edges(\"conversation\", should_continue)\n",
    "workflow.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "# Compile\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23b85e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEICAIAAAA4AWNJAAAQAElEQVR4nOzdB1gU1xoG4LOUZelFmkpX7IrGEsUYW6wxFmLvNdbYsGvsLcbeAMWOBSxIcq2JmtiiRA1qxEZTEekdFpZ2f5xkL1FYubB4Fvjeh4dndnZ2mNnd+fY/5ywzGnl5eQwA4KPTYAAAPCB9AIAPpA8A8IH0AQA+kD4AwAfSBwD4UE76vAmVxkXI0lNzWOWmIRbpGWhUqSquUk2LqbzcnLzwIGlitCwjPZcBKIlYoqZnpGFuLTYwESteUlTK7/tkyXJ/9IhgIpG+saa2bmWvpOh5j43IoGfU0ESjTR9TpsIiwzJ+PR4j1laztNPJycZ3vkBptLTVol5IRSJWrYbkkw7GCpYsVfpQ9Pi5RTi1q2Jpp82ggHuXY0V57HMXFQ2g6FcZV33jOgyqqilWYwBl49qpSCtH7UafGRa1QKnefFT1IHoK9UkH0+ysvLuXE5jqyc7KPbn1dZcR1RE9UKbauFiG/pUW8jC1qAVK/v6jvh5qcCF6iuLUzuSvG0l5uSrXqLl3OcGprTEDKHtUnQT8llTUvSVPH+pmNjDWZFAEsUQ9L5elJGYzFRP9SmZoJmYAZc/YQpxfphSh5OlDI1zaehiwV0RbXyM9WeXGAaUpORgfgI9DTU1EndAZaYUfBXgXAgAfSB8A4APpAwB8IH0AgA+kDwDwgfQBAD6QPgDAB9IHAPhA+gAAH0gfAOAD6QMAfCB9AIAPnOEFKpRTvt4dO7Vg8CFLls5xnTWRcVWO02fpsrnnL/zE/n+9Xb54ExnBoCJq0rjZ9GnzGBSm4CHTo4dL368HM67Kcfo8e/aY/f+ioiKTkhIZVFD29jW+6uHCoDAFD5nmzVq2atWGcVUO+n3OnD194uSRN29ea2lJnBp9MmXyLHNzi/Ydm9Fd369btmPnhp/8fs3JyTl4aPelS+djYqMNDAxbO7cd/800be388y5S3otEIhsbO5/jXkMGj96zdyfNHDykZ+vWbVcu38CgGAp9CZ48DZw4abjbzoN1atcTFhs6rHfr1u0mTpju9+OJffvdlyxeu33H+oiI8GrVrObPXR4c/OzQ4T0JCXENGjSeP3eZkVH++RX7fN1pyOBRYWEh165fyc3J6d6998ABw9dvXPnwwZ/aOjqjRk7o2uUrWqyYr+/iRWuoqqW3xKWf/X///dqCRTPe2ZFDB32tqltnZ2d7Hd5z+crFqKg3ZmYW/foO6dWz7wefhLi42J1uG/3/uCkSqTX9pMXECTPoSaD50dFRbu6b7t69Lc2QWlvbDhowolOn7jT/xYvQkaP7bdzgfvLU0YcPA9TU1Nq36zR5kmtGRoZL304jhn8zeNBIYc1ZWVk0p+dXfceNnZKYmLDTfdP9+3fpM9LBwZHmUDVHy/ie9qFnYNbMRfTkdO70JT3JDx786bl3R2hoED05NWrUGjt6spPTJ7RkQkK8m8fme/f8U1KSae9ceg9wcRlI8985ZKjllZqasmG9Wwl2QV1dnSmDqtc+9BSv37Dya5dBezy916zekpScuGxFfl3tc+ws/f52ymyvQ340QcfGkaP7R4+etGf3sTmzl9y4+Ru9MMIaNDU1Q0KDnj1/snb11m5dey7+bg3N9HD3ouOBQTEU9RIooKGhkZaW+p//nNq8abeP9zk6upYsnf1nwB3PXUf37z3x9GkgJYV8SZqmNDl96pdx476l6Xnzpw4eONLv9OUunXts3rI2OSWZFfv1rVevoXwbmjRpTlkj/Bzcf7KWY50aNRzNzfLzwt1ji7fPoSGDRtEeUfRQRFK8Kt4jCizaMErSZUt/oA8tCuL5C6fl5ubSrs2eO/lV+IsVyzfs2+PzeZsOq9cuvnHjN3qIukb+Rzsd6nQw+/leWrRwFSXI1WuXdXV1P23RmtJWvnI67FNTUzt26EornDvv20ePHsyds9TDzYtinf5oSEiQsJsZGdJTvsforl69+kml0gWLptvZOmzfum/n9gM1HBznLZgqPFfr1i8PfPTgu4Wr6dmmgNvhtvH6jV/Ze4eMXAl2gSmJqtc+oWHBWlpa9AFIb9Pq1ayWfLc2MuoNzacPQPqto6Nj+Hbii47dmjdr5eBQk6atrGzat+t82/+GsIY8xuhNs3XLHsO/H6JLv/X1DehNwKAYinoJFKPDdcCA4fp6+jRNBxvFx47t+yVv0Yd5UNBT+ZI1a9YWmgAd2nfZtHkNJUj9+o2Em4e89oS/ekFziv/6ytEfojJHmN5/YNfriFfubl5isZiOc78fj1PB1aVLj/y1Vbd+/vwJRduX3Xsr2B2KzqDgZ5R9wja4ui46fHhvbGwMtWVevgzb5XHYsWZtmj9yxPi79/x9T3tTZS08sO3nXwi7Q+VStarVKXmpfGjfvvPyFfNjYqLNzMzprt+uXqIGI63Z/4/fKUap1hDqHaox79y9TYkzy3UR1XdUNFFPTctPW7O3VUlaWlqnL7rb2toLS7Zr20msmX/CXKpNqEihv0XTVMj4+R2/c+fWZ63bvXPIyN2+faMEu8CUQdXTh14Get6nTh/bvVuvpk0/rWpZzcSkyvuLGRoaXfz5DBWlsbHR9L6XStO1tXXk99Jr8M4zDsVXzJfgfdZWtsIEBT299YWmFnv7ARAVHfn+Ynp6evk3re3ki9Hv1LT8KyKU5vWlA/iQl+fSJd8LYUQNQFpDs6Yt5Qs4OTWl2ic9PZ2OzKJWQilDySVED6EDlVbI8tukvhTNNWvUki9Zq1ZdaiHKb1JVIp/W09Onxg5NtGrZhsKRSpI+vfvTxtz8/Wr/fkNp/uPHf1GN09ipqbA8hUijhk0KJrW8uKMIpr1etWYRtdeaNWtJ29O48d+P0pZoHzm2PyDgDrXdqJii9lf1f1K4UM+DnpRgF5RC1dOH2vNUWx71PrBr97aUjavq1m1AMV+vboN3Ftu2/Yeffzk7Y9r8+g2ctMRaR48duHzlgvxeXV09BiVVzJfgfXQgyafp0C1qsXfuoiOh4E3henMlfn2pvli5aiGVDG0+ay/MSU9Po98zXMdTpBb8E/EJcQrSh45hiaSQy7dQONJ8+aryN0ZHV/gTf+9dYbtD0UMBdO3aZUofqqqSk5M6dOgibBu1g7p0c5YvT306BbNevqfU87J1syc9D2fO+O723G5hYTl65MTOnb+kLJszbwo9il4jG2s7WmzRYlemUMl2QSnKQa8zNdcXLVhJTyj1e+3Zt3PBwulCC1aO7jp7zm/Y0LFCVxlJS0tloDyFvgQF36+CjMwMVgZK/PrSoUhdVJSe1HcrnykcwAsXrHSwr1lwYaFLqChUuNEBSQfeO3utp6tHhVjB+WnpacX5tKPG17Ll85KSkyiDqKKhilLYNsri3R5HCi5JFVBRm0R9z/RDffbUX7bm+yW2dg6yzEzqJ9qyaXejRk2ExZISE4SVF6XEu1B6qt7rTLUodcKxt2FPteXoUROpnoyPjxPuFWKYykt6gxr8U3tTe5hKWcUJrcT8rvCKegl0hZbRP3U4DbXQqBArAyV4fQXUu0xdQjQQpqHxv09ZGkiiooy2llJJ+KE1U8tOQXXG3nZOUZYFBj4UbtIBP37C0NDQ4Nq16slkMuqskS9JPb516tRnH9KiuTNVef7+N6kHnfqbhZn0QFob7ax828RiLVNT8/cfHvHm9fXrvwrTdnYOM2csoJAKCw3OlGWyf3pFCb1wNAhY8Ll6/3kr8S6Unqqnz23/mwu/m0ndcq8jwp8HPT116pilRVWqM7Xeuv/gHs2kzKZ274WL/6FlgoOf01jAp5+2plKZ+tLoHfPOCg30Dej3rVvX6Q3EoBiKegnMzS2F7hh6klNSU7ZuW2dQNp1rFBbFf33laFCJxokpK6kiC3/9SvihLmfqXerRw2X/AQ8acadjmBo+s+ZMWrtuqeJtoA5X6vT5YcOKP+7cogJww6ZVdJxTz0uLFs7U77thw8rHTx7R5lEj6MnTQBpHYx9C715n57bePgdpiF3eiUt/hfZ09ZrvAgLuUmr8cun8N+MHUx/5+w+PjopcsmwOlTz0JLx69YI6tih9qIai7huKUeqopk8C2lR6UZo3a0njWZS2BQ+Zgs9biXeh9FS95TV0yOjs7Cx3982xcTFUDTZo4LR2zVahRBw0cOQx7wO//37N69Dp2bMW/7B++egx/S0tq9Ebrm6dBo/+uj9x8nDP3cfeWSH1qNHT7ea+qWGDxjS4wOBDinoJ6F0+b27+l0e+6tWOkmjsmMnRMVFUp7AyUPzXV44+YOj3ho2rCs6k8WaXPgMmTZhBg3G7dm+lQ5R6VZxbfT5m9GTFG0D7u3rl5m07fli6bI66mjp1VC+cv1Ioqdat3b7TbeOcuZNpTIpacyuWrf+kSXNWDB3adV7wyzlKB2NjE2EOVZffr93m5rGZkoXG12lnhw0bW2gQUBE6d/YSnxNe+/a706NsbR3o71Ia0l1zZi/x9NxOnwr0Vqfh+ZjY6BUr58+cNYFG0wseMvJV0V6UeBdKSVTiNoj/hXhZRv71ghkU4eye8LYuppZ2EqZKjm8Kb9rJ1MxatbYKKirvH0KGzreV6BbyBUX8jzsA8PHx0ofq80LnUx+bmpr6e+Mnf/M65FdGX9Wh1jv1IBR6F3XCaWqKC90kGxv7Hdv2MahwFLwfWFm+Dyuzj5c+u/49jignk2VqamiKihhWFL4sWxaoVVzUJtGAro62TqGbRJvKoCJS8H5gZfk+rMw+Xvoo/tLBx0f9/6q2ScAR3g8fH/p9AIAPpA8A8IH0AQA+kD4AwAfSBwD4QPoAAB9IHwDgA+kDAHwgfQCAj5Kf30eiq56bi3N0KaIpFmlJVO4MSvomGtlZZXIeDID3SXQ1NLUKPwpKfmxUsRRHvyyTM2lWDHSER73MMLYUMxVjYKIRG5HJAMpefFSmmhpT1yj8n8hLnj7VakiyZTmpSVkMChPyIKVBKwOmeuq2MHj5GOe9ho8h5EFyfecij4KSp49IJOo2quoN36iM9BwG/xYWmEJHeJs+Zkz1GFuIm3Y0+vX4h6/JBVAaD67F5+XkObUxKmoBUSnPr54Um+Wz6ZV9Q30jM7G2fmXvw1ZXF8VHZsqk2Ykxsp7jq6mpiZiqenon5a+bScaWEgsbCVPh7YRyR0NDFBOeIZPm5GTldhqq6EohIqVc3eHRraTol5lpSTyLIFmW7PXr1/Z29owfHQN1iY6auY1WTadycDoY+uQIeZiakpCdHJfNAJRE31hToiuytJfY1vnA5YJFFebaMmFhYa6uridPnmQAUB7g+z4AwAfSBwD4QPoAAB9IHwDgA+kDAHwgfQCAD6QPAPCB9AEAPpA+AMAH0gcA+ED6AAAfSB8A4APpAwB8IH0AgA+kDwDwgfQBAD6QPgDAB9IHAPhA+gAAH0gfAOAD6QMAfCB9AIAPpA8A8FFx0kckEllYWDAAKCcqTvrk5eVFRUUxACgn0PICAD6QPgDAB9IHAPhA+gAAH0gfAOAD6QMAfCB9AIAPpA8A8IH0P2FpcgAAD7BJREFUAQA+kD4AwAfSBwD4QPoAAB9IHwDgA+kDAHwgfQCAD1FeXh4rz4YOHZqUlCQSibKysuLi4iwtLWmmTCY7f/48AwAVpsbKub59+1LoRERExMTE5ObmRrylplbu9wugwiv3R2nv3r1tbGzemdmyZUsGAKqtItQI/fv3F4vF8ptmZmbDhw9nAKDaKkL6uLi4VK9eXZimbqzWrVvb2dkxAFBtFaR/ZMiQIVpaWjRhZWU1YsQIBgAqr4KkD/X+COUPFT7W1tYMAFTeh0fcszJz497I0lNzmGrz9/c/d+7cpEmTqN+HqTCRiBlW0TQy11RTEzGASuwD6XP1VExQQKquoYa2Hr6XqBw6BuqRoVKJnnoDZ4M6zQwYQGWlKH3O7XtjXFVSv5UxA2XLzc377XhkTSfdep8igKCSKjJ9fj4cZWShVae5EYMyc/loRL2WBo6N9RhA5VN4r3PUq4wMaS6ip6w597J4eD2JAVRKhadP/BuZhib+WaHMSXTU499kSlW+Rx+gLBQeMWnJ2UamYgZlz8JWOyk2iwFUPoWPZOXmsJzs8v2/7+WF6n+VAaCMYBwdAPhA+gAAH0gfAOAD6QMAfCB9AIAPpA8A8IH0AQA+kD4AwAfSBwD4QPoAAB9IHwDgA//IXrglS+e4zprIAKDMoPb5H9/TPk+fBc6bs5Sme/Rwyc7Cv54DlCGkz/88e/ZYPt28Ga6GClC2lJY+WVlZ+w94XPz5TGpqSs2atcePm9qggRPNl8lke/buvPLrxYSE+CpVTL/o2G3kiPEaGvl/t8/XnYYNGRMVHXn5ygWpNL1hwyazZi6SSLRd+nYaMfybwYNGytdMc3p+1Xfc2CmJiQk73Tfdv383KSnRwcGR5jRp3IyWCQ0NHj12wKoVG3d5btOWaLvtPPjgwZ+ee3eEhgbl5OTUqFFr7OjJTk6f0JK0GW4em+/d809JSTYzs3DpPcDFZSDNnz7zm/v379HEhQv/2eVx2MtrD+3IhvVuCnbhxYvQkaP7bdzgfvLU0YcPA9TU1Nq36zR5kqu6ujoDgA9RWr+Pm/umM2dPT5o4c/Om3dWrW8+ZNyXizWuav3nL2nPnf5wwfvr+fSfGjJ7se9rbY9dW4SF0AB/1PmBn53D08E97PX2eP39yyMtTV1f30xatr12/Il/z3bu3U1NTO3bompubO3fet48ePZg7Z6mHm1ed2vXmzZ8aEhJEy2hqatLvAwd3Deg/bPasxVKpdMGi6Xa2Dtu37tu5/UANB8d5C6YmpyTTMuvWLw989OC7has9dx2lgNvhtvH6jV9p/srlG2s51unQvvPpU7842NcsuGtF7YL62wzdsXPDoAEj/HwvLVq4itpuV69dZgBQDMqpfdLS0ih6xn8zjT786abrjIXS9PTXr1/p6uhSNTRh/DQ6qml+9WpWL1+Gnjh55Jtx3wp5YWtj361rT5owN7do0dz56dNAmm7fvvPyFfNjYqLNzMzp5m9XL9nb13BwqOn/x+/Pnj+hWkOod6ZMnnXn7u1TvsdmuS7Kv0oWY40bNxPWRlUJbVKnL7rb2toLS7Zr20msmX+2RqpNqEipVjX/0oPW1rZ+fsfv3Ln1Wet2enp6lCaaYrGh4b/OZk1FVlG7ICzQ9vMv6tdvRBNNP2lBq6VdEJ4EAFBMOekTFhZMzZO6deoLNylZli1dRxP3/vyDGj716jaUL1m7dr2MjIzw8JcUKHSTWk/yu/T1DYTypFXLNhKJhEqSPr37Z2dn3/z9av9+Q2n+48d/0ZobOzUVlqcQadSwSVDQU/ka6tX7+w9ZWdlQsqxas4jaa82atXSsWbtx478fRe2yI8f2BwTcoVihYoraX1SpKdi14JDnRe0CRRXdrFFgF/T09Km9xgCgGJSTPilvU0NLS/LO/PT0NPqto6Mrn6OtrUO/qZdHuClcfF1OuLgnRQ8F0LVrlyl9/gy4k5yc1KFDF2Ft1AfUpZuzfHnKBROTKvKburp/X5qGel62bvY8euzAmTO+uz23W1hYjh45sXPnLynLqElIj6JqyMbajhZbtNiVKaRgF4T0Ef97Fz54bVgAECgnfQyN8q84KByoBQlxUHC+MC2PiaJQ42vZ8nlJyUmUQVTRVLWsJjxKLBbv9jhScEmqgApdg5GR8cQJ0+knLCzE57jXmu+X2No5yDIzqZ9oy6bdjRo1ERZLSkwQVl6UEu8CACimnF5naytbKljuP7gn3KQWzbQZ42jwiBpWVF/89ei+fEnqM6YeFsWNHUJ9QFQW+fvfvHHzN+pvFmbWqVOf2ndUudjY2Ak/YrGWqan5+w+nDu/r138VpqlXe+aMBRRSYaHBmbJMmmNgYCjfmDeREQWrlfcrlxLvAgAoppz0oaORunsPH9l78eKZp88eb9y0+tmzxw0aNjY0MHw7fx9lQVRUJOWR34/Hv3YZJIy4K0DR4+zc1tvnIA2xyztxqVuXenBWr/kuIOAupcYvl85/M34wrfD9h0dHRS5ZNodKnpcvw169ekFDaZQ+VEPVrFGLqifqqI6Li/3jzq2t29Y1b9byVfgLGkqnR+nr6VMv0vOgp9QlJF9ViXcBABRT2iFEA14iNTX3XVuoQ8TevuaaVVtoeIjmT/12DnWabN66lnLE3Mxi6JAx8i/yKNahXecFv5yjdDA2NhHmUA3y/dptbh6bKVkyMqSWltWGDRvbr++Q9x9LfcxzZy/xOeG1b787PcrW1mHFsvXUD013zZm9xNNzOw1j1apVl0buY2KjV6ycP3PWhH17fPr0Gbhm7eKp08YsW/pDwbWVeBcAQIHCr+PufyFelsGc2pkwKGNn94S3dTG1tJMwgEoGzQcA4APpAwB8IH0AgA+kDwDwgfQBAD6QPgDAB9IHAPhA+gAAH0gfAOAD6QMAfCB9AIAPpA8A8IH0AQA+Ck8fiY56bk4ug7Knb6yhriFiAJVP4WcXMzTVeBMmZVD2Qh6kmllpMYDKp/D0sXLUkUlzGJSxiND0Oi30GUClVHj6UFvg064mFw++ZlBmpGnZ105Gte9vzgAqJZGCK8C8DpZeOBjZuK2JkYWWjj76p5VDpMYSomSpiVkBV+KHLbTR0sZll6GSEim+/lRqYva9ywmRYRnpKareEKMdkclk71wgTAUZmWpSxWnlqN3sC5y4Fio1UYW5+l1YWJirq+vJkycZAJQHaE8BAB9IHwDgA+kDAHwgfQCAD6QPAPCB9AEAPpA+AMAH0gcA+ED6AAAfSB8A4APpAwB8IH0AgA+kDwDwgfQBAD6QPgDAB9IHAPhA+gAAH0gfAOAD6QMAfCB9AIAPpA8A8IH0AQA+kD4AwEfFSR+RSOTg4MAAoJyoOOmTl5cXEhLCAKCcQMsLAPhA+gAAH0gfAOAD6QMAfCB9AIAPpA8A8IH0AQA+kD4AwAfSBwD4QPoAAB9IHwDgA+kDAHwgfQCAD6QPAPCB9AEAPkR5eXmsPBs/frxUKqW9yMjICA8Pd3R0pGmZTObt7c0AQIWV+9qnefPm7u7u8puBgYH029LSkgGAalNj5dyAAQOsra3fmenk5MQAQLWV+/TR19fv1q1bwTlU+AwcOJABgGor9+lDKGusrKyEaer0adSoUcOGDRkAqLaKkD4GBgZffvmlMF21atVBgwYxAFB5FSF9CCWOra0tTTR8iwGAylP+mFdyXJZITcQ+NkmPrv18fX2/7jU0JSGbfXQiEdMzwpenAP4PSvu+T0SI9N7lhLBH6VXttVMSslglY1pdKyJYWrOx3ucuphqaFaSiBChTykmfF4/Tb52Na93LwsBUUyT6+IWPSpBl5MRHZv58KGLMcnstHXUGAAopIX3CAtP+uJjQdZQVg7eDbgeXB0/ZWJMBgEJKaCP8eSWx45BqDN6i0q/9AMtrp2MZAChU2vRJisuibmZNMXo6/segivjF4zQGAAqVNjUSY7KqO+owKMDITEz9PuX933cBylppB4nzcllqEocRbhUXFZZRaXvfAYoJX1EBAD6QPgDAB9IHAPhA+gAAH0gfAOAD6QMAfCB9AIAPpA8A8IH0AQA+kD4AwAfSBwD4qFz/mz5qTP8tW79nAKACUPsAAB9IHwDgo9ykT3Z2ttfhPZevXIyKemNmZtGv75BePfsKd/X5utOwIWOioiMvX7kglaY3bNhk1sxFVaqY0l0PHwZs2fb9ixehlpbVxo6ZzABAZZSbfh93jy3ePoeGDBq1x9Obomf7jvVnzp4W7tLQ0DjqfcDOzuHo4Z/2evo8f/7kkJcnzU9NTV343UwDfUP3nYcWLlj5448n4uJwwlMAVVE+ah/KEb8fjw8ZPKpLlx5006q6NUXMkaP7v+zeW1jA1sa+W9eeNGFubtGiufPTp4E0fev29ZSU5KnfzqFgopvz5i7rP7A7AwDVUD5qn+DgZ9Tyata0pXyOk1PTiIjw9PR04aaDg6P8Ln19g+SUZJp48SJEIpEI0UPMzMzphwGAaigftU96ev5J2me4jpefrlQ4a3J8QpyOTv5ZpbW0tAouLyyULk3X0pIUnK+tjVNQA6iK8pE+urp69Jv6bhzs/3WdLHMzCwWPkmhJ0tJSC85JTU1hAKAaykf6UMNKU1MzISHepq2dMCcxMYHqILFYrOBRNtZ21F4LCwsRGl8hIUHx8XEMAFRD+UgfPT29Hj1c9h/wMDQ0qlOnPg2679i5gcbd16zarOBRLVt+Ru2yrdvWjRv3bXZW1u49242NTRgAqIZy832fSRNm6Ovp79q9lUbNTUyqOLf6fMzoD3x/h6Jq+bL1NDY/ddoYC4uq48ZOOXHyCC6zBaAiSnsd97DA9ICriR0H4UrK/3JgadCUTbiUO4Ai+E8LAODjY6fPTNcJz4OevD8/JyeHijANDfVCH+V1yM/QwJApyZGj+48e21/EnTRYX3gx6LnrmIWFJQMAJfnY6UOj5rIs2fvzZbJMSp93vrYjRz0+THm++urr9u07F3pXakqKnn7hf0v4xzEAUJaPnT6qcAxTlhUZZyhuAD4W9PsAAB9IHwDgA+kDAHwgfQCAD6QPAPCB9AEAPpA+AMAH0gcA+ED6AAAfpT2vs0gtT89Qk8G/VXXQxqk8ABQrbfqYWIhfPU1jUEBCVGZmeo78FNQAUKjSpo++sWaVquKM9BwG/0iKkdnVx+nrAT5ACVfUad7Z+OdDrxm8lZ6cdfOnaOce+Id4gA8QKaV7IvplxvlDkc49LQxNxRIddVYppSRkUZvr2smosSvtNcTl5iKxALyIlNU5mhAlu/NLQlhgmr6JZnJsFqtkLGwkibGyGk66n/U0YwBQDCKlD81kpOWKKuEHf16eVmUt+gBKRoSBYQDgAt82BAA+kD4AwAfSBwD4QPoAAB9IHwDgA+kDAHz8FwAA//8ly71YAAAABklEQVQDAKnFDxyC/CnKAAAAAElFTkSuQmCC",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "# LLM\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0) \n",
    "\n",
    "# State \n",
    "class State(MessagesState):\n",
    "    summary: str\n",
    "\n",
    "# Define the logic to call the model\n",
    "def call_model(state: State, config: RunnableConfig):\n",
    "    \n",
    "    # Get summary if it exists\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # If there is summary, then we add it\n",
    "    if summary:\n",
    "        \n",
    "        # Add summary to system message\n",
    "        system_message = f\"Summary of conversation earlier: {summary}\"\n",
    "\n",
    "        # Append summary to any newer messages\n",
    "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "    \n",
    "    else:\n",
    "        messages = state[\"messages\"]\n",
    "    \n",
    "    response = model.invoke(messages, config)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def summarize_conversation(state: State):\n",
    "    \n",
    "    # First, we get any existing summary\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # Create our summarization prompt \n",
    "    if summary:\n",
    "        \n",
    "        # A summary already exists\n",
    "        summary_message = (\n",
    "            f\"This is summary of the conversation to date: {summary}\\n\\n\"\n",
    "            \"Extend the summary by taking into account the new messages above:\"\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        summary_message = \"Create a summary of the conversation above:\"\n",
    "\n",
    "    # Add prompt to our history\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    # Delete all but the 2 most recent messages\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "    return {\"summary\": response.content, \"messages\": delete_messages}\n",
    "\n",
    "# Determine whether to end or summarize the conversation\n",
    "def should_continue(state: State):\n",
    "    \n",
    "    \"\"\"Return the next node to execute.\"\"\"\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # If there are more than six messages, then we summarize the conversation\n",
    "    if len(messages) > 6:\n",
    "        return \"summarize_conversation\"\n",
    "    \n",
    "    # Otherwise we can just end\n",
    "    return END\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"conversation\", call_model)\n",
    "workflow.add_node(summarize_conversation)\n",
    "\n",
    "# Set the entrypoint as conversation\n",
    "workflow.add_edge(START, \"conversation\")\n",
    "workflow.add_conditional_edges(\"conversation\", should_continue)\n",
    "workflow.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "# Compile\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f847a787-b301-488c-9b58-cba9f389f55d",
   "metadata": {},
   "source": [
    "### Streaming full state\n",
    "\n",
    "Now, let's talk about ways to [stream our graph state](https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming).\n",
    "\n",
    "`.stream` and `.astream` are sync and async methods for streaming back results. \n",
    " \n",
    "LangGraph supports a few [different streaming modes](https://langchain-ai.github.io/langgraph/how-tos/stream-values/) for [graph state](https://langchain-ai.github.io/langgraph/how-tos/stream-values/):\n",
    " \n",
    "* `values`: This streams the full state of the graph after each node is called.\n",
    "* `updates`: This streams updates to the state of the graph after each node is called.\n",
    "\n",
    "![values_vs_updates.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbaf892d24625a201744e5_streaming1.png)\n",
    "\n",
    "Let's look at `stream_mode=\"updates\"`.\n",
    "\n",
    "Because we stream with `updates`, we only see updates to the state after node in the graph is run.\n",
    "\n",
    "Each `chunk` is a dict with `node_name` as the key and the updated state as the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a6f8ae9-f244-40c5-a2da-618b72631b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conversation': {'messages': AIMessage(content=\"Hi Lance! It's great to hear from you. How can I help you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 61, 'total_tokens': 79, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d8864f8b6b', 'id': 'chatcmpl-BTjDzrfJqNitcr3Ja5ICJRoQCXfrb', 'finish_reason': 'stop', 'logprobs': None}, id='run-885a93b2-cc3f-44cd-b02d-50895616dbfa-0', usage_metadata={'input_tokens': 61, 'output_tokens': 18, 'total_tokens': 79, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}}\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "output = graph.stream({\"messages\": [HumanMessage(content=\"hi! I'm Lance\")]}, config, stream_mode=\"updates\")\n",
    "for chunk in output:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4882e9-07dd-4d70-866b-dfc530418cad",
   "metadata": {},
   "source": [
    "Let's now just print the state update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c859c777-cb12-4682-9108-6b367e597b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi again, Lance! It's great to hear from you. Is there anything specific you'd like to discuss or need assistance with today?\n"
     ]
    }
   ],
   "source": [
    "# Start conversation\n",
    "# for chunk in graph.stream({\"messages\": [HumanMessage(content=\"hi! I'm Lance\")]}, config, stream_mode=\"updates\"):\n",
    "#     chunk['conversation'][\"messages\"].pretty_print()\n",
    "output = graph.stream({\"messages\": [HumanMessage(content=\"hi! I'm Lance\")]}, config, stream_mode=\"updates\")\n",
    "for chunk in output:\n",
    "    chunk['conversation'][\"messages\"].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583bf219-6358-4d06-ae99-c40f43569fda",
   "metadata": {},
   "source": [
    "Now, we can see `stream_mode=\"values\"`.\n",
    "\n",
    "This is the `full state` of the graph after the `conversation` node is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ee763f8-6d1f-491e-8050-fb1439e116df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "---------------------------------------------------------------------------\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello, Lance! How can I assist you today?\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"hi! I'm Lance\")\n",
    "for event in graph.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
    "    for m in event['messages']:\n",
    "        m.pretty_print()\n",
    "    print(\"---\"*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563c198a-d1a4-4700-b7a7-ff5b8e0b25d7",
   "metadata": {},
   "source": [
    "### Streaming tokens\n",
    "\n",
    "We often want to stream more than graph state.\n",
    "\n",
    "In particular, with chat model calls it is common to stream the tokens as they are generated.\n",
    "\n",
    "We can do this [using the `.astream_events` method](https://langchain-ai.github.io/langgraph/how-tos/streaming-from-final-node/#stream-outputs-from-the-final-node), which streams back events as they happen inside nodes!\n",
    "\n",
    "Each event is a dict with a few keys:\n",
    " \n",
    "* `event`: This is the type of event that is being emitted. \n",
    "* `name`: This is the name of event.\n",
    "* `data`: This is the data associated with the event.\n",
    "* `metadata`: Contains`langgraph_node`, the node emitting the event.\n",
    "\n",
    "Let's have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ae8c7a6-c6e7-4cef-ac9f-190d2f4dd763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node: . Type: on_chain_start. Name: LangGraph\n",
      "Node: conversation. Type: on_chain_start. Name: conversation\n",
      "Node: conversation. Type: on_chat_model_start. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_end. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chain_start. Name: should_continue\n",
      "Node: conversation. Type: on_chain_end. Name: should_continue\n",
      "Node: conversation. Type: on_chain_stream. Name: conversation\n",
      "Node: conversation. Type: on_chain_end. Name: conversation\n",
      "Node: . Type: on_chain_stream. Name: LangGraph\n",
      "Node: . Type: on_chain_end. Name: LangGraph\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    print(f\"Node: {event['metadata'].get('langgraph_node','')}. Type: {event['event']}. Name: {event['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b63490f-3d24-4f68-95ca-5320ccb61d2d",
   "metadata": {},
   "source": [
    "The central point is that tokens from chat models within your graph have the `on_chat_model_stream` type.\n",
    "\n",
    "We can use `event['metadata']['langgraph_node']` to select the node to stream from.\n",
    "\n",
    "And we can use `event['data']` to get the actual data for each event, which in this case is an `AIMessageChunk`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc3529f8-3960-4d41-9ed6-373f93183950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='The', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' San', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Francisco', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' are', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' professional', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' American', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' football', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' based', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' San', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Francisco', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Bay', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Area', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' They', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' compete', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' National', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Football', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' League', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='NFL', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=')', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' as', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' member', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' league', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=\"'s\", additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' National', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Football', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Conference', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='N', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='FC', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=')', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' West', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' division', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' was', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' founded', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='194', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='6', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' as', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' charter', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' member', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' All', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='-Amer', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='ica', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Football', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Conference', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='AA', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='FC', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=')', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' joined', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' NFL', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='194', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='9', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' when', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' leagues', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' merged', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='###', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Key', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Points', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=':\\n\\n', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='St', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='adium', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' play', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' their', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' home', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' games', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' at', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Levi', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=\"'s\", additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Stadium', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Santa', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Clara', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' California', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' which', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' they', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' moved', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='201', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='4', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Before', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' that', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' they', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' played', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' at', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Cand', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='lestick', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Park', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' San', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Francisco', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='Team', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Colors', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=\" team's\", additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' colors', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' are', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' red', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' gold', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' white', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='Masc', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='ot', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=\"'\", additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' mascot', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' S', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='ourd', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='ough', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Sam', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='Champ', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='ionship', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='s', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' won', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' five', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Super', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Bowl', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' titles', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='X', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='VI', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' XIX', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' XX', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='III', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' XX', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='IV', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' XX', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='IX', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='),', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' with', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' their', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' most', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' successful', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' period', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' being', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='198', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='0', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='s', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' early', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='199', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='0', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='s', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' They', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' also', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' won', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' numerous', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' division', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' titles', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' conference', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' championships', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='Not', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='able', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Players', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' has', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' had', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' several', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Hall', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Fame', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' players', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' including', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Joe', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Montana', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Jerry', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Rice', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Steve', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Young', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Ronnie', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' L', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='ott', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Charles', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Haley', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' among', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' others', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='Co', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='aching', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Management', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' has', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' been', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' led', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' by', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' several', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' notable', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' coaches', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' including', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Bill', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Walsh', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' who', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' credited', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' with', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' popular', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='izing', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' \"', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='West', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Coast', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Off', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='ense', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='.\"', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' As', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='202', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='3', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' season', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' head', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' coach', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Kyle', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Shan', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='ahan', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='R', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='ival', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='ries', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' notable', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' rival', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='ries', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' with', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Seattle', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Seahawks', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Los', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Angeles', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Rams', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' historically', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' with', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Dallas', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Cowboys', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Green', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Bay', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Packers', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='Ownership', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' owned', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' by', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' York', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' family', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' with', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' Jed', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' York', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' serving', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' as', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' CEO', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='The', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' are', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' known', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' for', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' their', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' rich', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' history', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' strong', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' fan', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' base', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' They', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' are', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' considered', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' one', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' most', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' successful', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' franchises', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' NFL', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' history', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' both', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' terms', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' championships', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' their', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' influence', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' on', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content=' game', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n",
      "{'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f5bdcc3276'}, id='run-a76cf1c1-4726-4897-8b48-85e187af8051')}\n"
     ]
    }
   ],
   "source": [
    "node_to_stream = 'conversation'\n",
    "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    # Get chat model tokens from a particular node \n",
    "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
    "        print(event[\"data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226e569a-76c3-43d8-8f89-3ae687efde1c",
   "metadata": {},
   "source": [
    "As you see above, just use the `chunk` key to get the `AIMessageChunk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3aeae53d-6dcf-40d0-a0c6-c40de492cc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|The| San| Francisco| |49|ers| are| a| professional| American| football| team| based| in| the| San| Francisco| Bay| Area|.| They| compete| in| the| National| Football| League| (|NFL|)| as| a| member| club| of| the| league|'s| National| Football| Conference| (|N|FC|)| West| division|.| The| team| was| founded| in| |194|6| as| a| charter| member| of| the| All|-Amer|ica| Football| Conference| (|AA|FC|)| and| joined| the| NFL| in| |194|9| when| the| leagues| merged|.\n",
      "\n",
      "|###| Key| Points|:\n",
      "\n",
      "|-| **|St|adium|**|:| The| |49|ers| play| their| home| games| at| Levi|'s| Stadium| in| Santa| Clara|,| California|,| which| they| moved| to| in| |201|4|.| Before| that|,| they| played| at| Cand|lestick| Park| in| San| Francisco|.\n",
      "\n",
      "|-| **|Team| Colors|**|:| The| team's| colors| are| red|,| gold|,| and| white|.\n",
      "\n",
      "|-| **|Masc|ot|**|:| The| |49|ers|'| mascot| is| S|ourd|ough| Sam|.\n",
      "\n",
      "|-| **|Champ|ionship|s|**|:| The| |49|ers| have| won| five| Super| Bowl| titles| (|X|VI|,| XIX|,| XX|III|,| XX|IV|,| and| XX|IX|),| with| their| most| successful| period| being| the| |198|0|s| and| early| |199|0|s|.| They| have| also| won| numerous| division| titles| and| conference| championships|.\n",
      "\n",
      "|-| **|Not|able| Players|**|:| The| team| has| had| several| Hall| of| Fame| players|,| including| Joe| Montana|,| Jerry| Rice|,| Steve| Young|,| Ronnie| L|ott|,| and| Charles| Haley|,| among| others|.\n",
      "\n",
      "|-| **|Co|aching| and| Management|**|:| The| team| has| been| led| by| several| notable| coaches|,| including| Bill| Walsh|,| who| is| credited| with| popular|izing| the| West| Coast| offense|.| As| of| my| last| update|,| the| head| coach| is| Kyle| Shan|ahan|.\n",
      "\n",
      "|-| **|R|ival|ries|**|:| The| |49|ers| have| notable| rival|ries| with| the| Seattle| Seahawks|,| Los| Angeles| Rams|,| and| historically| with| the| Dallas| Cowboys| and| Green| Bay| Packers|.\n",
      "\n",
      "|-| **|Ownership|**|:| The| team| is| owned| by| the| York| family|,| with| Jed| York| serving| as| the| CEO|.\n",
      "\n",
      "|The| |49|ers| are| known| for| their| rich| history| and| have| a| strong| fan| base|.| They| are| one| of| the| most| successful| teams| in| NFL| history|,| both| in| terms| of| championships| and| overall| win|-loss| record|.||"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"5\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    # Get chat model tokens from a particular node \n",
    "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
    "        data = event[\"data\"]\n",
    "        print(data[\"chunk\"].content, end=\"|\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5826e4d8-846b-4f6c-a5c1-e781d43022db",
   "metadata": {},
   "source": [
    "### Streaming with LangGraph API\n",
    "\n",
    "** DISCLAIMER**\n",
    "\n",
    "Since the filming of these videos, we've updated Studio so that it can be run locally and opened in your browser. This is now the preferred way to run Studio (rather than using the Desktop App as shown in the video). See documentation [here](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/#local-development-server) on the local development server and [here](https://langchain-ai.github.io/langgraph/how-tos/local-studio/#run-the-development-server). To start the local development server, run the following command in your terminal in the `/studio` directory in this module:\n",
    "\n",
    "```\n",
    "langgraph dev\n",
    "```\n",
    "\n",
    "You should see the following output:\n",
    "```\n",
    "-  API: http://127.0.0.1:2024\n",
    "-  Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n",
    "-  API Docs: http://127.0.0.1:2024/docs\n",
    "```\n",
    "\n",
    "Open your browser and navigate to the Studio UI: `https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024`.\n",
    "\n",
    "The LangGraph API [supports editing graph state](https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_edit_state/#initial-invocation). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8925b632-512b-48e1-9220-61c06bfbf0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    raise Exception(\"Unfortunately LangGraph Studio is currently not supported on Google Colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079c2ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_sdk import get_client\n",
    "\n",
    "# This is the URL of the local development server\n",
    "URL = \"http://127.0.0.1:2024\"\n",
    "client = get_client(url=URL)\n",
    "\n",
    "# Search all hosted graphs\n",
    "assistants = await client.assistants.search()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d15af9e-0e86-41e3-a5ba-ee2a4aa08a32",
   "metadata": {},
   "source": [
    "Let's [stream `values`](https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_values/), like before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63e3096f-5429-4d3c-8de2-2bddf7266ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StreamPart(event='metadata', data={'run_id': '1ef6a3d0-41eb-66f4-a311-8ebdfa1b281f'})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '345c67cf-c958-4f89-b787-540fc025080c', 'example': False}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '345c67cf-c958-4f89-b787-540fc025080c', 'example': False}, {'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'type': 'ai', 'name': None, 'id': 'run-88179a6d-eb1e-4953-ac42-0b533b6d76f6', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '345c67cf-c958-4f89-b787-540fc025080c', 'example': False}, {'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'type': 'ai', 'name': None, 'id': 'run-88179a6d-eb1e-4953-ac42-0b533b6d76f6', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '4dd5ce10-ac0b-4a91-b34b-c35109dcbf29', 'tool_call_id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'artifact': None, 'status': 'success'}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '345c67cf-c958-4f89-b787-540fc025080c', 'example': False}, {'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'type': 'ai', 'name': None, 'id': 'run-88179a6d-eb1e-4953-ac42-0b533b6d76f6', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '4dd5ce10-ac0b-4a91-b34b-c35109dcbf29', 'tool_call_id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'artifact': None, 'status': 'success'}, {'content': 'The result of multiplying 2 and 3 is 6.', 'additional_kwargs': {}, 'response_metadata': {'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'type': 'ai', 'name': None, 'id': 'run-b5862486-a25f-48fc-9a03-a8506a6692a8', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}]})\n"
     ]
    }
   ],
   "source": [
    "# Create a new thread\n",
    "thread = await client.threads.create()\n",
    "# Input message\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], \n",
    "                                      assistant_id=\"agent\", \n",
    "                                      input={\"messages\": [input_message]}, \n",
    "                                      stream_mode=\"values\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556dc7fd-1cae-404f-816a-f13d772b3b14",
   "metadata": {},
   "source": [
    "The streamed objects have: \n",
    "\n",
    "* `event`: Type\n",
    "* `data`: State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57b735aa-139c-45a3-a850-63519c0004f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "content='Multiply 2 and 3' additional_kwargs={'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'example': False} id='f51807de-6b99-4da4-a798-26cf59d16412'\n",
      "=========================\n",
      "content='' additional_kwargs={'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_imZHAw7kvMR2ZeKaQVSlj25C', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'example': False, 'invalid_tool_calls': [], 'usage_metadata': None} id='run-fa4ab1c6-274d-4be5-8c4a-a6411c7c35cc' tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_imZHAw7kvMR2ZeKaQVSlj25C', 'type': 'tool_call'}]\n",
      "=========================\n",
      "content='6' additional_kwargs={'additional_kwargs': {}, 'response_metadata': {}, 'status': 'success'} name='multiply' id='3e7bbfb6-aa82-453a-969c-9c753fbd1d74' tool_call_id='call_imZHAw7kvMR2ZeKaQVSlj25C'\n",
      "=========================\n",
      "content='The result of multiplying 2 and 3 is 6.' additional_kwargs={'additional_kwargs': {}, 'response_metadata': {'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'example': False, 'invalid_tool_calls': [], 'usage_metadata': None} id='run-e8e0d672-cfb2-42be-850a-345df3718f69'\n",
      "=========================\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import convert_to_messages\n",
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], assistant_id=\"agent\", input={\"messages\": [input_message]}, stream_mode=\"values\"):\n",
    "    messages = event.data.get('messages',None)\n",
    "    if messages:\n",
    "        print(convert_to_messages(messages)[-1])\n",
    "    print('='*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a555d186-27be-4ddf-934c-895a3105035d",
   "metadata": {},
   "source": [
    "There are some new streaming mode that are only supported via the API.\n",
    "\n",
    "For example, we can [use `messages` mode](https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_messages/) to better handle the above case!\n",
    "\n",
    "This mode currently assumes that you have a `messages` key in your graph, which is a list of messages.\n",
    "\n",
    "All events emitted using `messages` mode have two attributes:\n",
    "\n",
    "* `event`: This is the name of the event\n",
    "* `data`: This is data associated with the event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4abd91f6-63c0-41ee-9988-7c8248b88a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata\n",
      "messages/complete\n",
      "messages/metadata\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/complete\n",
      "messages/complete\n",
      "messages/metadata\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/complete\n"
     ]
    }
   ],
   "source": [
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], \n",
    "                                      assistant_id=\"agent\", \n",
    "                                      input={\"messages\": [input_message]}, \n",
    "                                      stream_mode=\"messages\"):\n",
    "    print(event.event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de2f1ea-b232-43fc-af7a-320efce83381",
   "metadata": {},
   "source": [
    "We can see a few events: \n",
    "\n",
    "* `metadata`: metadata about the run\n",
    "* `messages/complete`: fully formed message \n",
    "* `messages/partial`: chat model tokens\n",
    "\n",
    "You can dig further into the types [here](https://langchain-ai.github.io/langgraph/cloud/concepts/api/#modemessages).\n",
    "\n",
    "Now, let's show how to stream these messages. \n",
    "\n",
    "We'll define a helper function for better formatting of the tool calls in messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50a85e16-6e3f-4f14-bcf9-8889a762f522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: Run ID - 1ef6a3da-687f-6253-915a-701de5327165\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
      "Response Metadata: Finish Reason - tool_calls\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "AI: The\n",
      "--------------------------------------------------\n",
      "AI: The result\n",
      "--------------------------------------------------\n",
      "AI: The result of\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying \n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and \n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is \n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is 6\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is 6.\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is 6.\n",
      "Response Metadata: Finish Reason - stop\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "\n",
    "def format_tool_calls(tool_calls):\n",
    "    \"\"\"\n",
    "    Format a list of tool calls into a readable string.\n",
    "\n",
    "    Args:\n",
    "        tool_calls (list): A list of dictionaries, each representing a tool call.\n",
    "            Each dictionary should have 'id', 'name', and 'args' keys.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string of tool calls, or \"No tool calls\" if the list is empty.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if tool_calls:\n",
    "        formatted_calls = []\n",
    "        for call in tool_calls:\n",
    "            formatted_calls.append(\n",
    "                f\"Tool Call ID: {call['id']}, Function: {call['name']}, Arguments: {call['args']}\"\n",
    "            )\n",
    "        return \"\\n\".join(formatted_calls)\n",
    "    return \"No tool calls\"\n",
    "\n",
    "async for event in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id=\"agent\",\n",
    "    input={\"messages\": [input_message]},\n",
    "    stream_mode=\"messages\",):\n",
    "    \n",
    "    # Handle metadata events\n",
    "    if event.event == \"metadata\":\n",
    "        print(f\"Metadata: Run ID - {event.data['run_id']}\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    # Handle partial message events\n",
    "    elif event.event == \"messages/partial\":\n",
    "        for data_item in event.data:\n",
    "            # Process user messages\n",
    "            if \"role\" in data_item and data_item[\"role\"] == \"user\":\n",
    "                print(f\"Human: {data_item['content']}\")\n",
    "            else:\n",
    "                # Extract relevant data from the event\n",
    "                tool_calls = data_item.get(\"tool_calls\", [])\n",
    "                invalid_tool_calls = data_item.get(\"invalid_tool_calls\", [])\n",
    "                content = data_item.get(\"content\", \"\")\n",
    "                response_metadata = data_item.get(\"response_metadata\", {})\n",
    "\n",
    "                if content:\n",
    "                    print(f\"AI: {content}\")\n",
    "\n",
    "                if tool_calls:\n",
    "                    print(\"Tool Calls:\")\n",
    "                    print(format_tool_calls(tool_calls))\n",
    "\n",
    "                if invalid_tool_calls:\n",
    "                    print(\"Invalid Tool Calls:\")\n",
    "                    print(format_tool_calls(invalid_tool_calls))\n",
    "\n",
    "                if response_metadata:\n",
    "                    finish_reason = response_metadata.get(\"finish_reason\", \"N/A\")\n",
    "                    print(f\"Response Metadata: Finish Reason - {finish_reason}\")\n",
    "                    \n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae885f8-102f-448a-9d68-8ded8d2bbd18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
